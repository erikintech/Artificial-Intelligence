{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6112d48-ec64-4901-a0e0-cd8cdbc56256",
   "metadata": {},
   "source": [
    "# <div align=center>**Introduction to Classification** </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b2bdb3-efc6-4121-ab05-84bf8234dc2f",
   "metadata": {},
   "source": [
    "Classification is a type of supervised learning where the machine learning algorithms to learn how to assign a class label to an observation.\n",
    "\n",
    "For example we can classify an email as *spam* and *not spam*, or we can recognize a photo if it is a cat or a dog, other example is determine the posibility of customer churn in a company or if someone can get a heart attack"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b4f2fa-0a13-4a79-9b09-c15750b118b3",
   "metadata": {},
   "source": [
    "## **Types of Classification Problems**\n",
    "\n",
    "* **Binary Classification**\n",
    "   * **Definition**\n",
    "     * Classification tasks that have two class labels\n",
    "   * **Examples**\n",
    "      * 0/1, yes/not\n",
    "      * Emailspam detection (spam/not spam)\n",
    "      * Churn prediction (churn or not)\n",
    "      * Conversion prediction (byt or not)\n",
    "   * **Algorithms**\n",
    "      * Logistic Regression\n",
    "      * K-Nearest Neighbors\n",
    "      * Decision Tree\n",
    "      * Suppport Vector Machines\n",
    "      * Nive Bayes\n",
    "* **Multi-Class Classification**\n",
    "  * **Definition**\n",
    "    * Classification tasks that have two or mor class labels\n",
    "  * **Examples**  \n",
    "    * Face detection\n",
    "    * Plant species classification\n",
    "    * Optical character recognition\n",
    "    **Algorithms** \n",
    "      * K-Nearest Neighbors\n",
    "      * Decision Tree\n",
    "      * Naive Bayes\n",
    "      * Random Forest\n",
    "      * Gradient Boosting\n",
    "* **Multi-Label Classification**\n",
    "   * **Definition**\n",
    "     * Classification tasks that have two or more class labels, where one or more class labels may be predicted for each example\n",
    "   * **Examples**\n",
    "      * Objects detection\n",
    "      * Movie genre recognition\n",
    "   * **Algorithms** \n",
    "      * Multi-label decision tree\n",
    "      * Multi-label random forest\n",
    "      * Multi-label gradient boosting\n",
    "* **Imbalanced Classification**\n",
    "   * **Definition**\n",
    "     * Classificationtasks where the number of examples in each class is unequality destributed,  typically  imbalanced classification tasks are binary classification tasks.\n",
    "   * **Examples**:\n",
    "     * Fraud detection\n",
    "     * Outlier detection\n",
    "     * Medical diagnostic tests.\n",
    "   * **How to dealing with these tasts**\n",
    "     * We have two option:\n",
    "       * Undersampling\n",
    "       * Oversampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e142974-54ae-4494-8577-5deb21518d08",
   "metadata": {},
   "source": [
    "## **Evaluation Metrics for Classification Tasks**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41af06f1-69b4-48e4-ab61-2755efb872a6",
   "metadata": {},
   "source": [
    "### **Confusion Matrix**\n",
    "\n",
    "Confusion matrix is a performance measurement for ml classification tasks where the output can be two or more classes, it is a table with combination of predicted and actual values.\n",
    "\n",
    "<div align=center> <img src='confusion-matrix.webp' width=450 /> </div>\n",
    "\n",
    "    For example we are creating a classification model to predict if a student pass or not the semester, so we have the next\n",
    "\n",
    "* **Positive class** -> Passed\n",
    "* **Negative class** -> Failed\n",
    "\n",
    "* **True Positives (TP)** = the number of cases correctly identified as passed\n",
    "* **True Negative (TN)** = the number of cases correctly identified as failed\n",
    "* **False Positive (FP)** = the number of cases incorrectly indentified as passed\n",
    "* **False Negative (FN)** = the number of cases incorrectly indentified as failed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0bef8f7-3c55-4eab-9168-975e732db3d2",
   "metadata": {},
   "source": [
    "### **Accuracy**\n",
    "Accuracy simply measures how often the classifier correctly predicts.\n",
    "\n",
    "$Accuracy = \\frac{TP+TN}{TP+TN+FP+FN}$\n",
    "\n",
    "Accuracy is useful when er have a dataset with a target class **well balanced**, but is not a good choice when we have **unbalanced classes**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cecb30d2-2f37-4861-a2d3-fec8a4981632",
   "metadata": {},
   "source": [
    "### **Precisiony**\n",
    "\n",
    "Precision explains how many of the correctly predicted cases actually turned out to be positive.\n",
    "\n",
    "The importance of **Precision** *is in music and video recommendation systems, e-commerce websites, etc, where wrong results could lead to customer churn and this could be harmful to the business*\n",
    "\n",
    "$Precision = \\frac{TP}{TP + FP}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1a8356-f96f-4c40-a239-296dd858cf7e",
   "metadata": {},
   "source": [
    "### **Racall**\n",
    "\n",
    "**Recall | Sensitivity** explains how many of the actual positive cases we were able to predict corecctly with our model.\n",
    "\n",
    "$ Recall = \\frac{TP}{TP + FN} $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19d1b37-ccb6-4115-8f50-83880471f2ee",
   "metadata": {},
   "source": [
    "### **F1-Score**\n",
    "\n",
    "F1 Score gives a combination idea about Precision and Recall. It is maximun when Precision is eaqual to Recall\n",
    "\n",
    "$ F1 = 2 \\frac{Precision * Recall}{Precision  +  Recall} $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b94e138-10b1-4cd4-a111-4d591db9417e",
   "metadata": {},
   "source": [
    "### **Log-Loss**\n",
    "\n",
    "Logistic loss or Cross-Entropy Loss, is one of the most metrics to assess the performance of a classification model.\n",
    "\n",
    "For a single sample with true label $y \\in [0,1]$ and a probability estimate $p = Pr(y = 1)$, the log loss is:\n",
    "\n",
    "$losloss_(N = 1) = ylog(p) + (1 - y) log(1 - p)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665557ad-fb12-43eb-ace4-e0952402962b",
   "metadata": {},
   "source": [
    "### **AUC-ROC**\n",
    "\n",
    "The **Receiver Operator Characteristic** is a probability curve that plots the True Positive Rate against the False Positive Rate at various threshold values and separates the signal from the noise\n",
    "\n",
    "**Area Under Curve** is the measure of the ability of a classifier to distinguish between classes..\n",
    "\n",
    "* If AUC is 0 the classifier would be predicting Negative classes as Positive classes.\n",
    "* If AUC is 0.5 the classifier is not able to distinguishbetween Positives and Negatives\n",
    "* If AUC is 1 the classifier is able to perfectly distinguish between all Positive and Negative classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc438df-2476-4deb-b1dc-ab70af478210",
   "metadata": {},
   "source": [
    "### **Conclusion**\n",
    "\n",
    "Metrics like Accuracy, Precision, Recall are good when we have a balanced data set, but if the data is imbalanced then other methods like ROC/AUC perform better in evaluation the model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aeb62da-da3a-45e8-bfde-625c54e8e186",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "orion",
   "language": "python",
   "name": "orion"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
